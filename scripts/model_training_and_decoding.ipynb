{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drug_generation_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_2jy3gUF_KV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e1e272a4-0dc2-4ad5-ee42-882d81716a48"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nf_PgQ5ySJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp /content/drive/My\\ Drive/model.ckpt-600000* /tmp/t2t/output/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaZ3aRRfyVO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cd /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpYz-i4fyYk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload data\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzO8UhPDq-mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip prot_lig_binding_human_ds5.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7fxvxhCfp3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable Eager execution - useful for seeing the generated data.\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "\n",
        "# Set a seed so that we have deterministic outputs.\n",
        "RANDOM_SEED = 301\n",
        "trainer_lib.set_random_seed(RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZFv_mcfwr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Setup and create directories.\n",
        "DATA_DIR = os.path.expanduser(\"/tmp/t2t/data\")\n",
        "OUTPUT_DIR = os.path.expanduser(\"/tmp/t2t/output\")\n",
        "TMP_DIR = os.path.expanduser(\"/tmp/t2t/tmp\")\n",
        "USR_DIR = os.path.expanduser(\"/tmp/t2t/usr\")\n",
        "\n",
        "# Create them.\n",
        "tf.gfile.MakeDirs(DATA_DIR)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "tf.gfile.MakeDirs(TMP_DIR)\n",
        "tf.gfile.MakeDirs(USR_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksKwM3jT-ynU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir transformer_scratch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGpkyVqwPenb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cd /tmp/t2t/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vJy_ljPeuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload vocab file\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAPW15g1PjeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBqYYHtAEfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile transformer_scratch/prob.py\n",
        "\n",
        "import re\n",
        "\n",
        "  \n",
        "  \n",
        "# `Problem` is the base class for any dataset that we want to add to T2T -- it\n",
        "# unifies the specification of the problem for generating training data,\n",
        "# training, evaluation and inference.\n",
        "#\n",
        "# All its methods (except `generate_data`) have reasonable default\n",
        "# implementations.\n",
        "#\n",
        "# A sub-class must implement `generate_data(data_dir, tmp_dir)` -- this method\n",
        "# is called by t2t-trainer or t2t-datagen to actually generate TFRecord dataset\n",
        "# files on disk.\n",
        "from tensor2tensor.data_generators import problem\n",
        "\n",
        "# Certain categories of problems are very common, like where either the input or\n",
        "# output is text, for such problems we define an (abstract) sub-class of\n",
        "# `Problem` called `Text2TextProblem` -- this implements `generate_data` in\n",
        "# terms of another function `generate_samples`. Sub-classes must override\n",
        "# `generate_samples` and `is_generate_per_split`.\n",
        "from tensor2tensor.data_generators import text_problems\n",
        "\n",
        "# Every non-abstract problem sub-class (as well as models and hyperparameter\n",
        "# sets) must be registered with T2T so that T2T knows about it and can look it\n",
        "# up when you specify your problem on the commandline to t2t-trainer or\n",
        "# t2t-datagen.\n",
        "#\n",
        "# One uses:\n",
        "# `register_problem` for a new Problem sub-class.\n",
        "# `register_model` for a new T2TModel sub-class.\n",
        "# `register_hparams` for a new hyperparameter set. All hyperparameter sets\n",
        "# typically extend `common_hparams.basic_params1` (directly or indirectly).\n",
        "from tensor2tensor.utils import registry\n",
        "\n",
        "\n",
        "# By default, when you register a problem (or model or hyperparameter set) the\n",
        "# name with which it gets registered is the 'snake case' version -- so here\n",
        "# the Problem class `ProteinSpecificLigandGeneration` will be registered with\n",
        "# the name `protein_specific_ligand_generation`.\n",
        "#\n",
        "# One can override this default by actually assigning a name as follows:\n",
        "# `@registry.register_problem(\"my_awesome_problem\")`\n",
        "#\n",
        "# The registered name is specified to the t2t-trainer or t2t-datagen using the\n",
        "# commandline flag `--problem`.\n",
        "@registry.register_problem('protein_specific_ligand_generation')\n",
        "\n",
        "# We inherit from `Text2TextProblem` which takes care of a lot of details\n",
        "# regarding reading and writing the data to disk, what vocabulary type one\n",
        "# should use, its size etc -- so that we need not worry about them, one can,\n",
        "# of course, override those.\n",
        "\n",
        "\n",
        "class ProteinSpecificLigandGeneration(text_problems.Text2TextProblem):\n",
        "  \n",
        "\n",
        "  # START: Methods we should override.\n",
        "\n",
        "  # The methods that need to be overriden from `Text2TextProblem` are:\n",
        "  # `is_generate_per_split` and\n",
        "  # `generate_samples`.\n",
        "\n",
        "  @property\n",
        "  def is_generate_per_split(self):\n",
        "    # If we have pre-existing data splits for (train, eval, test) then we set\n",
        "    # this to True, which will have generate_samples be called for each of the\n",
        "    # dataset_splits.\n",
        "    #\n",
        "    # If we do not have pre-existing data splits, we set this to False, which\n",
        "    # will have generate_samples be called just once and the Problem will\n",
        "    # automatically partition the data into dataset_splits.\n",
        "    return False\n",
        "\n",
        "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
        "    # Here we are generating the data in-situ using the `sample_sentence`\n",
        "    # function, otherwise we would have downloaded the data and put it in\n",
        "    # `tmp_dir` -- and read it from that location.\n",
        "    del tmp_dir\n",
        "\n",
        "    # Unused here, is used in `Text2TextProblem.generate_data`.\n",
        "    del data_dir\n",
        "\n",
        "    # This would have been useful if `self.is_generate_per_split()` was True.\n",
        "    # In that case we would have checked if we were generating a training,\n",
        "    # evaluation or test sample. This is of type `problem.DatasetSplit`.\n",
        "    del dataset_split\n",
        "\n",
        "    \n",
        "  #  drug_file = open (\"drugs.smi.txt\", \"r\")\n",
        "  \n",
        "  \n",
        "   \n",
        "    with open(\"/content/proteins_train.space_sep_seq\") as file1, open(\"/content/ligands_train.space_sep_seq\") as file2:\n",
        "      for x, y in zip(file1, file2):\n",
        "        inputs = x.strip()\n",
        "        targets = y.strip()\n",
        "        yield {\"inputs\":inputs,\"targets\":targets}\n",
        "     \n",
        "    \n",
        "    \n",
        "  # END: Methods we should override.\n",
        "\n",
        "  # START: Overridable methods.\n",
        "\n",
        "  @property\n",
        "  def vocab_type(self):\n",
        "    # We can use different types of vocabularies, `VocabType.CHARACTER`,\n",
        "    # `VocabType.SUBWORD` and `VocabType.TOKEN`.\n",
        "    #\n",
        "    # SUBWORD and CHARACTER are fully invertible -- but SUBWORD provides a good\n",
        "    # tradeoff between CHARACTER and TOKEN.\n",
        "    return text_problems.VocabType.TOKEN\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  @property\n",
        "  def dataset_splits(self):\n",
        "    # Since we are responsible for generating the dataset splits, we override\n",
        "    # `Text2TextProblem.dataset_splits` to specify that we intend to keep\n",
        "    # 80% data for training and 10% for evaluation and testing each.\n",
        "    return [{\n",
        "        \"split\": problem.DatasetSplit.TRAIN,\n",
        "        \"shards\": 196504,\n",
        "    }, {\n",
        "        \"split\": problem.DatasetSplit.EVAL,\n",
        "        \"shards\": 0,\n",
        "    }, {\n",
        "        \"split\": problem.DatasetSplit.TEST,\n",
        "        \"shards\": 0,\n",
        "    }]\n",
        "\n",
        " # END: Overridable methods.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CuAwlDVDL3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile transformer_scratch/__init__.py\n",
        "\n",
        "from transformer_scratch import prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RMDmY3dELbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! t2t-datagen \\\n",
        "  --problem=protein_specific_ligand_generation \\\n",
        "  --data_dir=/tmp/t2t/data \\\n",
        "  --tmp_dir=/tmp/t2t/tmp \\\n",
        "  --t2t_usr_dir=/content/transformer_scratch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40YyojYzJre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! t2t-trainer \\\n",
        "  --model=transformer \\\n",
        "  --hparams_set=transformer_tiny \\\n",
        "  --hparams=\"batch_size=4096,max_length=0,label_smoothing=0,learning_rate_decay_scheme='noam',num_hidden_layers=4\" \\\n",
        "  --problem=protein_specific_ligand_generation \\\n",
        "  --worker_gpu=1 \\\n",
        "  --train_steps=5000000 \\\n",
        "  --schedule=train \\\n",
        "  --data_dir=/tmp/t2t/data \\\n",
        "  --output_dir=/tmp/t2t/output \\\n",
        "  --t2t_usr_dir=/content/transformer_scratch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oskaPzjVPuG6",
        "colab_type": "code",
        "outputId": "841c99ec-1129-4984-f406-d2e1d1da090e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd /tmp/t2t/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/t2t/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f0yw7SnPyZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkx5vqY9CiRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip proteins_test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNmc7olXP6jh",
        "colab_type": "code",
        "outputId": "665625f7-24fa-47f9-8e7d-b4de216e5192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "% cd /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5REALoFEUfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensor2tensor.bin import t2t_decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh0sqNKIFXPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! t2t-decoder \\\n",
        "  --hparams_set=transformer_tiny \\\n",
        "  --hparams=\"batch_size=4096,max_length=0,label_smoothing=0,learning_rate_decay_scheme='noam',num_hidden_layers=4\" \\\n",
        "  --decode_hparams=\"beam_size=4,alpha=0.6,batch_size=4\" \\\n",
        "  --model=transformer \\\n",
        "  --problem=protein_specific_ligand_generation \\\n",
        "  --data_dir=/tmp/t2t/data \\\n",
        "  --output_dir=/tmp/t2t/output \\\n",
        "  --t2t_usr_dir=/content/transformer_scratch \\\n",
        "  --decode_from_file=/tmp/t2t/data/proteins_test5.space_sep_seq_unique \\\n",
        "  --decode_to_file=protein.seq.decode.results_bs4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxGdamNZrWBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! t2t-decoder \\\n",
        "  --hparams_set=transformer_tiny \\\n",
        "  --hparams=\"batch_size=4096,max_length=0,label_smoothing=0,learning_rate_decay_scheme='noam',num_hidden_layers=4\" \\\n",
        "  --decode_hparams=\"beam_size=10,alpha=0.6,batch_size=4,write_beam_scores=False, return_beams=True\" \\\n",
        "  --model=transformer \\\n",
        "  --problem=protein_specific_ligand_generation \\\n",
        "  --data_dir=/tmp/t2t/data \\\n",
        "  --output_dir=/tmp/t2t/output \\\n",
        "  --t2t_usr_dir=/content/transformer_scratch \\\n",
        "  --decode_from_file=/tmp/t2t/data/proteins_test5.space_sep_seq_unique \\\n",
        "  --decode_to_file=protein.seq.decode.results_bs4_1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOI41mt2FYi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /tmp/t2t/output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOSGh_T0f9FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLrYWFCggXCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Doun1MlFFz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp model.ckpt-600000.* /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn2_HOqrDfJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzY5TSorNdmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adaL-_rHNeI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}